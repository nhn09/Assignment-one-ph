{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhn09/NLP-notebooks/blob/main/Thesis_3_29_23_pt_3_feature_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature extraction and Pre process"
      ],
      "metadata": {
        "id": "2SQrjkXDamWV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfY8gHP03aKM",
        "outputId": "6102b0f5-9988-4fa3-b38b-068b9a95e422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import nltk\n",
        "import spacy\n",
        "import gensim\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# !python -m spacy download en_core_web_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import LdaModel\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/translated_dataset.csv')\n",
        "df = df.drop(['post'], axis=1)"
      ],
      "metadata": {
        "id": "rLhCZb0j5mhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess_text(text):\n",
        "    return [token for token in simple_preprocess(text) if token not in stop_words]\n",
        "\n",
        "stop_words = gensim.parsing.preprocessing.STOPWORDS\n",
        "\n",
        "\n",
        "texts = [preprocess_text(text) for text in df['english_text']]\n",
        "\n",
        "dictionary = Dictionary(texts)\n",
        "\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "# Train the LDA model on the corpus\n",
        "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=10, passes=10)\n",
        "\n",
        "# Get the topic distribution for each document in the corpus\n",
        "topic_distributions = lda_model.get_document_topics(corpus)\n",
        "\n",
        "# Store the topic distributions in a new column in the dataframe\n",
        "df['topic_distributions'] = topic_distributions\n",
        "\n"
      ],
      "metadata": {
        "id": "h3OqLrzK5GEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "bow_matrix = vectorizer.fit_transform(df['english_text'])\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=10, random_state=42)\n",
        "lda.fit(bow_matrix)\n",
        "\n",
        "topic_proportions = lda.transform(bow_matrix)\n",
        "\n",
        "feature_matrix = pd.DataFrame(topic_proportions, columns=['topic_{}'.format(i) for i in range(10)])\n",
        "\n",
        "data_with_features = pd.concat([df, feature_matrix], axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "TXTbeRlI41Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_with_features.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEEva1215mYk",
        "outputId": "81c73bd0-edf7-40df-c312-90045e21adac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8692 entries, 0 to 8691\n",
            "Data columns (total 16 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   Mach                 8692 non-null   float64\n",
            " 1   LSRP12               8692 non-null   float64\n",
            " 2   LSRP2                8692 non-null   float64\n",
            " 3   NRSM                 8692 non-null   float64\n",
            " 4   english_text         8692 non-null   object \n",
            " 5   topic_distributions  8692 non-null   object \n",
            " 6   topic_0              8692 non-null   float64\n",
            " 7   topic_1              8692 non-null   float64\n",
            " 8   topic_2              8692 non-null   float64\n",
            " 9   topic_3              8692 non-null   float64\n",
            " 10  topic_4              8692 non-null   float64\n",
            " 11  topic_5              8692 non-null   float64\n",
            " 12  topic_6              8692 non-null   float64\n",
            " 13  topic_7              8692 non-null   float64\n",
            " 14  topic_8              8692 non-null   float64\n",
            " 15  topic_9              8692 non-null   float64\n",
            "dtypes: float64(14), object(2)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text analysis with TextBlob"
      ],
      "metadata": {
        "id": "O1amTqv8_HWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "!pip install textblob\n",
        "!pip install textstat\n",
        "from textblob import TextBlob\n",
        "from textstat import flesch_reading_ease, flesch_kincaid_grade\n",
        "\n",
        "# Load the data into a Pandas DataFrame\n",
        "data = data_with_features\n",
        "# Define a function to analyze the text and return the relevant metrics\n",
        "def analyze_text(text):\n",
        "    blob = TextBlob(text)\n",
        "    return {\n",
        "  'polarity': blob.sentiment.polarity,\n",
        "        'subjectivity': blob.sentiment.subjectivity,\n",
        "        'flesch_reading_ease': flesch_reading_ease(text),\n",
        "        'flesch_kincaid_grade': flesch_kincaid_grade(text),\n",
        "        'lexical_density': len(set(blob.words)) / (len(blob.words)+1),\n",
        "    }\n",
        "\n",
        "# Apply the function to each row of the DataFrame and store the results in separate columns\n",
        "data[['polarity', 'subjectivity', 'flesch_reading_ease', 'flesch_kincaid_grade', 'lexical_density']] = data['english_text'].apply(lambda x: pd.Series(analyze_text(x)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4wO-4Vh_K4Q",
        "outputId": "36fb1e1e-12fa-46bb-c8b4-1eb5e06cdd1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.9/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.9/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (1.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (4.65.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (8.1.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting textstat\n",
            "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyphen\n",
            "  Downloading pyphen-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.14.0 textstat-0.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "\n",
        "# Load the dataset\n",
        "df_2 = data\n",
        "\n",
        "# Define the functions for language style analysis\n",
        "def get_word_tokens(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "def get_word_count(tokens):\n",
        "    return len(tokens)\n",
        "\n",
        "def get_avg_word_length(tokens):\n",
        "    return sum(len(token) for token in tokens) / len(tokens)\n",
        "\n",
        "def get_word_freq_dist(tokens):\n",
        "    return FreqDist(tokens)\n",
        "\n",
        "def get_stopword_count(tokens):\n",
        "    stop_words = set(stopwords.words('english') + list(punctuation))\n",
        "    return len([token for token in tokens if token.lower() in stop_words])\n",
        "\n",
        "def get_part_of_speech(tokens):\n",
        "    return nltk.pos_tag(tokens)\n",
        "\n",
        "# Apply the functions to the text column and create new columns for the results\n",
        "df_2['word_tokens'] = df_2['english_text'].apply(get_word_tokens)\n",
        "df_2['word_count'] = df_2['word_tokens'].apply(get_word_count)\n",
        "df_2['avg_word_length'] = df_2['word_tokens'].apply(get_avg_word_length)\n",
        "df_2['word_freq_dist'] = df_2['word_tokens'].apply(get_word_freq_dist)\n",
        "df_2['stopword_count'] = df_2['word_tokens'].apply(get_stopword_count)\n",
        "df_2['part_of_speech'] = df_2['word_tokens'].apply(get_part_of_speech)\n",
        "\n",
        "# Preview the results\n",
        "print(df_2.head())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ky7XzvwNvFp",
        "outputId": "6082354e-5556-4ca9-86fc-7e557c02ba1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Mach  LSRP12  LSRP2  NRSM  \\\n",
            "0  68.0     1.3    2.5   3.0   \n",
            "1  68.0     1.3    2.5   3.0   \n",
            "2  68.0     1.3    2.5   3.0   \n",
            "3  68.0     1.3    2.5   3.0   \n",
            "4  68.0     1.3    2.5   3.0   \n",
            "\n",
            "                                        english_text  \\\n",
            "0                              my heart my soul..T-T   \n",
            "1              Free speech is a joke in this country   \n",
            "2  Make 500 sequels I don't care.Make another Jus...   \n",
            "3  Everybody wants a piece of the politically cor...   \n",
            "4                    And that's how a movement dies.   \n",
            "\n",
            "                                 topic_distributions   topic_0   topic_1  \\\n",
            "0  [(0, 0.033340164), (1, 0.36668393), (2, 0.0333...  0.020001  0.020000   \n",
            "1  [(0, 0.2994644), (1, 0.020006958), (2, 0.02000...  0.012502  0.012500   \n",
            "2  [(0, 0.012529142), (1, 0.012528878), (2, 0.012...  0.005556  0.005556   \n",
            "3  [(0, 0.29995903), (1, 0.5856051), (2, 0.014301...  0.899986  0.011111   \n",
            "4  [(0, 0.03336451), (1, 0.3661786), (2, 0.033364...  0.016667  0.016667   \n",
            "\n",
            "    topic_2   topic_3  ...  subjectivity  flesch_reading_ease  \\\n",
            "0  0.020001  0.819989  ...           0.0               118.18   \n",
            "1  0.012502  0.012500  ...           0.8               105.66   \n",
            "2  0.005558  0.005556  ...           0.4                62.85   \n",
            "3  0.011112  0.011112  ...           0.1                45.42   \n",
            "4  0.016670  0.144381  ...           0.0                99.23   \n",
            "\n",
            "   flesch_kincaid_grade  lexical_density  \\\n",
            "0                  -2.3         0.666667   \n",
            "1                   0.5         0.888889   \n",
            "2                   6.6         0.947368   \n",
            "3                   9.2         0.900000   \n",
            "4                   0.9         0.875000   \n",
            "\n",
            "                                         word_tokens  word_count  \\\n",
            "0                     [my, heart, my, soul, .., T-T]           6   \n",
            "1     [Free, speech, is, a, joke, in, this, country]           8   \n",
            "2  [Make, 500, sequels, I, do, n't, care.Make, an...          21   \n",
            "3  [Everybody, wants, a, piece, of, the, politica...           9   \n",
            "4         [And, that, 's, how, a, movement, dies, .]           8   \n",
            "\n",
            "   avg_word_length                                     word_freq_dist  \\\n",
            "0         3.000000  {'my': 2, 'heart': 1, 'soul': 1, '..': 1, 'T-T...   \n",
            "1         3.750000  {'Free': 1, 'speech': 1, 'is': 1, 'a': 1, 'jok...   \n",
            "2         4.476190  {'Make': 1, '500': 1, 'sequels': 1, 'I': 1, 'd...   \n",
            "3         5.222222  {'Everybody': 1, 'wants': 1, 'a': 1, 'piece': ...   \n",
            "4         3.250000  {'And': 1, 'that': 1, ''s': 1, 'how': 1, 'a': ...   \n",
            "\n",
            "   stopword_count                                     part_of_speech  \n",
            "0               2  [(my, PRP$), (heart, NN), (my, PRP$), (soul, N...  \n",
            "1               4  [(Free, JJ), (speech, NN), (is, VBZ), (a, DT),...  \n",
            "2               8  [(Make, NNP), (500, CD), (sequels, NNS), (I, P...  \n",
            "3               3  [(Everybody, NN), (wants, VBZ), (a, DT), (piec...  \n",
            "4               5  [(And, CC), (that, DT), ('s, VBZ), (how, WRB),...  \n",
            "\n",
            "[5 rows x 27 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_2.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nB5HkeOcOf-U",
        "outputId": "f13d0309-7768-477f-f228-eb8feb616f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8692 entries, 0 to 8691\n",
            "Data columns (total 27 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Mach                  8692 non-null   float64\n",
            " 1   LSRP12                8692 non-null   float64\n",
            " 2   LSRP2                 8692 non-null   float64\n",
            " 3   NRSM                  8692 non-null   float64\n",
            " 4   english_text          8692 non-null   object \n",
            " 5   topic_distributions   8692 non-null   object \n",
            " 6   topic_0               8692 non-null   float64\n",
            " 7   topic_1               8692 non-null   float64\n",
            " 8   topic_2               8692 non-null   float64\n",
            " 9   topic_3               8692 non-null   float64\n",
            " 10  topic_4               8692 non-null   float64\n",
            " 11  topic_5               8692 non-null   float64\n",
            " 12  topic_6               8692 non-null   float64\n",
            " 13  topic_7               8692 non-null   float64\n",
            " 14  topic_8               8692 non-null   float64\n",
            " 15  topic_9               8692 non-null   float64\n",
            " 16  polarity              8692 non-null   float64\n",
            " 17  subjectivity          8692 non-null   float64\n",
            " 18  flesch_reading_ease   8692 non-null   float64\n",
            " 19  flesch_kincaid_grade  8692 non-null   float64\n",
            " 20  lexical_density       8692 non-null   float64\n",
            " 21  word_tokens           8692 non-null   object \n",
            " 22  word_count            8692 non-null   int64  \n",
            " 23  avg_word_length       8692 non-null   float64\n",
            " 24  word_freq_dist        8692 non-null   object \n",
            " 25  stopword_count        8692 non-null   int64  \n",
            " 26  part_of_speech        8692 non-null   object \n",
            "dtypes: float64(20), int64(2), object(5)\n",
            "memory usage: 1.8+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_pos(pos_list):\n",
        "    pos_counts = {}\n",
        "    for pos in pos_list:\n",
        "        if pos[1] in pos_counts:\n",
        "            pos_counts[pos[1]] += 1\n",
        "        else:\n",
        "            pos_counts[pos[1]] = 1\n",
        "    return pos_counts\n",
        "\n",
        "# Apply the function to the 'pos' column to get the POS counts for each row\n",
        "df_2['pos_counts'] = df_2['part_of_speech'].apply(count_pos)\n",
        "\n",
        "# Convert the 'pos_counts' column to separate columns for each POS and its count\n",
        "df_2 = pd.concat([df_2.drop('pos_counts', axis=1), df_2['pos_counts'].apply(pd.Series)], axis=1)\n"
      ],
      "metadata": {
        "id": "8Xg3mROYUArj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2.fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "nSYjS3-BV2Cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiXB7DjWdk9P",
        "outputId": "ec4f34d1-790b-4bba-b850-201ed5b5e0d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8692 entries, 0 to 8691\n",
            "Data columns (total 71 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Mach                  8692 non-null   float64\n",
            " 1   LSRP12                8692 non-null   float64\n",
            " 2   LSRP2                 8692 non-null   float64\n",
            " 3   NRSM                  8692 non-null   float64\n",
            " 4   english_text          8692 non-null   object \n",
            " 5   topic_distributions   8692 non-null   object \n",
            " 6   topic_0               8692 non-null   float64\n",
            " 7   topic_1               8692 non-null   float64\n",
            " 8   topic_2               8692 non-null   float64\n",
            " 9   topic_3               8692 non-null   float64\n",
            " 10  topic_4               8692 non-null   float64\n",
            " 11  topic_5               8692 non-null   float64\n",
            " 12  topic_6               8692 non-null   float64\n",
            " 13  topic_7               8692 non-null   float64\n",
            " 14  topic_8               8692 non-null   float64\n",
            " 15  topic_9               8692 non-null   float64\n",
            " 16  polarity              8692 non-null   float64\n",
            " 17  subjectivity          8692 non-null   float64\n",
            " 18  flesch_reading_ease   8692 non-null   float64\n",
            " 19  flesch_kincaid_grade  8692 non-null   float64\n",
            " 20  lexical_density       8692 non-null   float64\n",
            " 21  word_tokens           8692 non-null   object \n",
            " 22  word_count            8692 non-null   int64  \n",
            " 23  avg_word_length       8692 non-null   float64\n",
            " 24  word_freq_dist        8692 non-null   object \n",
            " 25  stopword_count        8692 non-null   int64  \n",
            " 26  part_of_speech        8692 non-null   object \n",
            " 27  PRP$                  8692 non-null   float64\n",
            " 28  NN                    8692 non-null   float64\n",
            " 29  CD                    8692 non-null   float64\n",
            " 30  JJ                    8692 non-null   float64\n",
            " 31  VBZ                   8692 non-null   float64\n",
            " 32  DT                    8692 non-null   float64\n",
            " 33  IN                    8692 non-null   float64\n",
            " 34  NNP                   8692 non-null   float64\n",
            " 35  NNS                   8692 non-null   float64\n",
            " 36  PRP                   8692 non-null   float64\n",
            " 37  VBP                   8692 non-null   float64\n",
            " 38  RB                    8692 non-null   float64\n",
            " 39  VB                    8692 non-null   float64\n",
            " 40  CC                    8692 non-null   float64\n",
            " 41  TO                    8692 non-null   float64\n",
            " 42  :                     8692 non-null   float64\n",
            " 43  #                     8692 non-null   float64\n",
            " 44  WRB                   8692 non-null   float64\n",
            " 45  .                     8692 non-null   float64\n",
            " 46  WP                    8692 non-null   float64\n",
            " 47  VBG                   8692 non-null   float64\n",
            " 48  VBD                   8692 non-null   float64\n",
            " 49  PDT                   8692 non-null   float64\n",
            " 50  VBN                   8692 non-null   float64\n",
            " 51  JJR                   8692 non-null   float64\n",
            " 52  ``                    8692 non-null   float64\n",
            " 53  ''                    8692 non-null   float64\n",
            " 54  (                     8692 non-null   float64\n",
            " 55  )                     8692 non-null   float64\n",
            " 56  ,                     8692 non-null   float64\n",
            " 57  JJS                   8692 non-null   float64\n",
            " 58  $                     8692 non-null   float64\n",
            " 59  POS                   8692 non-null   float64\n",
            " 60  MD                    8692 non-null   float64\n",
            " 61  WDT                   8692 non-null   float64\n",
            " 62  NNPS                  8692 non-null   float64\n",
            " 63  RP                    8692 non-null   float64\n",
            " 64  SYM                   8692 non-null   float64\n",
            " 65  RBR                   8692 non-null   float64\n",
            " 66  EX                    8692 non-null   float64\n",
            " 67  UH                    8692 non-null   float64\n",
            " 68  FW                    8692 non-null   float64\n",
            " 69  RBS                   8692 non-null   float64\n",
            " 70  WP$                   8692 non-null   float64\n",
            "dtypes: float64(64), int64(2), object(5)\n",
            "memory usage: 4.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_2.to_csv(\"feature_dataset_8692.csv\")"
      ],
      "metadata": {
        "id": "_6mDErWBV9ET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Running Models\n"
      ],
      "metadata": {
        "id": "6xFdIQY5ugNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "import gensim\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9A5PSI_a_AS",
        "outputId": "dedf3d46-b454-4b37-c6eb-41c3eb4d4c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# For Mach\n",
        "\n",
        "this section showing result for without code switching, emoji and object columns in sevaral configurations:\n",
        "\n",
        "*   all columns\n",
        "*   all columns: scaled\n",
        "*   dropping colsum>=6000\n",
        "*   same, scaled\n",
        "*   dropping colsum>=4000\n",
        "*   same, scaled\n",
        "\n",
        "all of these done for NB,RF and SVM.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rujHeskQujgv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# with all columns\n"
      ],
      "metadata": {
        "id": "ZTmGJUTAvCxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/feature_dataset_8692.csv')\n",
        "y =(df.Mach<df.Mach.quantile()).replace({True:1, False:2})\n",
        "\n",
        "x = df.drop(['Mach', 'LSRP12','LSRP2','NRSM','english_text','topic_distributions','word_tokens','part_of_speech','word_freq_dist'], axis=1)\n"
      ],
      "metadata": {
        "id": "lOGGoygKvrLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "x_scaled = scaler.fit_transform(x.to_numpy())\n",
        "x_scaled = pd.DataFrame(x_scaled)\n",
        "\n",
        "print(\"Scaled Dataset Using MinMaxScaler\")\n",
        "x_scaled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "qQvxMNsXSg8i",
        "outputId": "3287d0f4-cd89-4d0f-8e29-e8d43d5c8be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled Dataset Using MinMaxScaler\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0         1         2         3         4         5         6   \\\n",
              "0  0.000000  0.020010  0.019990  0.020011  0.839355  0.020018  0.020283   \n",
              "1  0.000115  0.012497  0.012483  0.012498  0.012768  0.012503  0.012666   \n",
              "2  0.000230  0.005539  0.005533  0.005541  0.005659  0.005542  0.241820   \n",
              "3  0.000345  0.901597  0.011093  0.011106  0.011347  0.011113  0.011257   \n",
              "4  0.000460  0.016670  0.016653  0.016675  0.147768  0.016679  0.016899   \n",
              "\n",
              "         7         8         9   ...   53   54   55   56   57   58   59   60  \\\n",
              "0  0.020402  0.020158  0.019916  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "1  0.012740  0.012588  0.012413  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2  0.005647  0.005579  0.005467  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "3  0.011324  0.011186  0.011025  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "4  0.016996  0.016793  0.016581  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "\n",
              "    61   62  \n",
              "0  0.0  0.0  \n",
              "1  0.0  0.0  \n",
              "2  0.0  0.0  \n",
              "3  0.0  0.0  \n",
              "4  0.0  0.0  \n",
              "\n",
              "[5 rows x 63 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-663261e6-0c23-4b4a-bf45-f14935555d90\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020010</td>\n",
              "      <td>0.019990</td>\n",
              "      <td>0.020011</td>\n",
              "      <td>0.839355</td>\n",
              "      <td>0.020018</td>\n",
              "      <td>0.020283</td>\n",
              "      <td>0.020402</td>\n",
              "      <td>0.020158</td>\n",
              "      <td>0.019916</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000115</td>\n",
              "      <td>0.012497</td>\n",
              "      <td>0.012483</td>\n",
              "      <td>0.012498</td>\n",
              "      <td>0.012768</td>\n",
              "      <td>0.012503</td>\n",
              "      <td>0.012666</td>\n",
              "      <td>0.012740</td>\n",
              "      <td>0.012588</td>\n",
              "      <td>0.012413</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000230</td>\n",
              "      <td>0.005539</td>\n",
              "      <td>0.005533</td>\n",
              "      <td>0.005541</td>\n",
              "      <td>0.005659</td>\n",
              "      <td>0.005542</td>\n",
              "      <td>0.241820</td>\n",
              "      <td>0.005647</td>\n",
              "      <td>0.005579</td>\n",
              "      <td>0.005467</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000345</td>\n",
              "      <td>0.901597</td>\n",
              "      <td>0.011093</td>\n",
              "      <td>0.011106</td>\n",
              "      <td>0.011347</td>\n",
              "      <td>0.011113</td>\n",
              "      <td>0.011257</td>\n",
              "      <td>0.011324</td>\n",
              "      <td>0.011186</td>\n",
              "      <td>0.011025</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000460</td>\n",
              "      <td>0.016670</td>\n",
              "      <td>0.016653</td>\n",
              "      <td>0.016675</td>\n",
              "      <td>0.147768</td>\n",
              "      <td>0.016679</td>\n",
              "      <td>0.016899</td>\n",
              "      <td>0.016996</td>\n",
              "      <td>0.016793</td>\n",
              "      <td>0.016581</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 63 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-663261e6-0c23-4b4a-bf45-f14935555d90')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-663261e6-0c23-4b4a-bf45-f14935555d90 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-663261e6-0c23-4b4a-bf45-f14935555d90');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=42)\n",
        "\n",
        "nb_clf = GaussianNB()\n",
        "nb_clf.fit(X_train, y_train)\n",
        "nb_pred = nb_clf.predict(X_test)\n",
        "nb_acc = accuracy_score(y_test, nb_pred)\n",
        "print(\"Naive Bayes accuracy :\", nb_acc)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_scaled,y, test_size=0.3, random_state=42)\n",
        "\n",
        "nb_clf = GaussianNB()\n",
        "nb_clf.fit(X_train, y_train)\n",
        "nb_pred = nb_clf.predict(X_test)\n",
        "nb_acc = accuracy_score(y_test, nb_pred)\n",
        "print(\"Naive Bayes accuracy scaled:\", nb_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EHYXRxjbD7w",
        "outputId": "a1f4a062-a3c5-46e2-e1d4-3932f6f11d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes accuracy : 0.4988496932515337\n",
            "Naive Bayes accuracy scaled: 0.5011503067484663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_clf = SVC(kernel='linear', C=1, cache_size=2000)\n",
        "svm_clf.fit(X_train, y_train)\n",
        "svm_pred = svm_clf.predict(X_test)\n",
        "svm_acc = accuracy_score(y_test, svm_pred)\n",
        "print(\"SVM accuracy:\", svm_acc)"
      ],
      "metadata": {
        "id": "UaZduGJBfw82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=42)\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# fit the random forest classifier to the training data\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing data\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the random forest classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L41fPD45H-h6",
        "outputId": "891b4f12-34a9-4326-973b-886449e1768c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7246932515337423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_scaled,y, test_size=0.3, random_state=42)\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# fit the random forest classifier to the training data\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing data\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the random forest classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:(scaled)\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "203f995f-7c09-4cde-e35b-d73facdf2a36",
        "id": "IuOyrCHrTWMC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:(scaled) 0.7434815950920245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dropping columns = sum zero > 6000\n"
      ],
      "metadata": {
        "id": "oeu0R1lovFbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/feature_dataset_8692.csv')\n",
        "y =(df.Mach<df.Mach.quantile()).replace({True:1, False:2})\n",
        "\n",
        "\n",
        "\n",
        "for column_name in df.columns:\n",
        "    column = df[column_name]\n",
        "    # Get the count of Zeros in column\n",
        "    count = (column == 0).sum()\n",
        "\n",
        "    if (count>=6000):\n",
        "       print('Count of zeros in column ', column_name, ' is : ', count)\n",
        "       df.drop(columns =column_name, inplace = True )\n",
        "\n",
        "df = df.drop(['Mach', 'LSRP12','LSRP2','NRSM','english_text','topic_distributions','word_tokens','part_of_speech','word_freq_dist'], axis=1)\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbP8BNkFr7_Q",
        "outputId": "2dd232bf-47fe-4810-f2ac-c4a7108c6c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of zeros in column  PRP$  is :  7318\n",
            "Count of zeros in column  CD  is :  6608\n",
            "Count of zeros in column  VBZ  is :  6161\n",
            "Count of zeros in column  NNS  is :  6030\n",
            "Count of zeros in column  VBP  is :  6249\n",
            "Count of zeros in column  CC  is :  6924\n",
            "Count of zeros in column  TO  is :  6939\n",
            "Count of zeros in column  #  is :  7240\n",
            "Count of zeros in column  WRB  is :  7995\n",
            "Count of zeros in column  WP  is :  8006\n",
            "Count of zeros in column  VBG  is :  7069\n",
            "Count of zeros in column  VBD  is :  6790\n",
            "Count of zeros in column  PDT  is :  8536\n",
            "Count of zeros in column  VBN  is :  7439\n",
            "Count of zeros in column  JJR  is :  8367\n",
            "Count of zeros in column  ``  is :  8285\n",
            "Count of zeros in column  ''  is :  8158\n",
            "Count of zeros in column  (  is :  8170\n",
            "Count of zeros in column  )  is :  7693\n",
            "Count of zeros in column  ,  is :  6980\n",
            "Count of zeros in column  JJS  is :  8266\n",
            "Count of zeros in column  $  is :  8516\n",
            "Count of zeros in column  POS  is :  7972\n",
            "Count of zeros in column  MD  is :  7393\n",
            "Count of zeros in column  WDT  is :  8478\n",
            "Count of zeros in column  NNPS  is :  8589\n",
            "Count of zeros in column  RP  is :  8332\n",
            "Count of zeros in column  SYM  is :  8673\n",
            "Count of zeros in column  RBR  is :  8555\n",
            "Count of zeros in column  EX  is :  8438\n",
            "Count of zeros in column  UH  is :  8570\n",
            "Count of zeros in column  FW  is :  8569\n",
            "Count of zeros in column  RBS  is :  8610\n",
            "Count of zeros in column  WP$  is :  8681\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8692 entries, 0 to 8691\n",
            "Data columns (total 29 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Unnamed: 0            8692 non-null   int64  \n",
            " 1   topic_0               8692 non-null   float64\n",
            " 2   topic_1               8692 non-null   float64\n",
            " 3   topic_2               8692 non-null   float64\n",
            " 4   topic_3               8692 non-null   float64\n",
            " 5   topic_4               8692 non-null   float64\n",
            " 6   topic_5               8692 non-null   float64\n",
            " 7   topic_6               8692 non-null   float64\n",
            " 8   topic_7               8692 non-null   float64\n",
            " 9   topic_8               8692 non-null   float64\n",
            " 10  topic_9               8692 non-null   float64\n",
            " 11  polarity              8692 non-null   float64\n",
            " 12  subjectivity          8692 non-null   float64\n",
            " 13  flesch_reading_ease   8692 non-null   float64\n",
            " 14  flesch_kincaid_grade  8692 non-null   float64\n",
            " 15  lexical_density       8692 non-null   float64\n",
            " 16  word_count            8692 non-null   int64  \n",
            " 17  avg_word_length       8692 non-null   float64\n",
            " 18  stopword_count        8692 non-null   int64  \n",
            " 19  NN                    8692 non-null   float64\n",
            " 20  JJ                    8692 non-null   float64\n",
            " 21  DT                    8692 non-null   float64\n",
            " 22  IN                    8692 non-null   float64\n",
            " 23  NNP                   8692 non-null   float64\n",
            " 24  PRP                   8692 non-null   float64\n",
            " 25  RB                    8692 non-null   float64\n",
            " 26  VB                    8692 non-null   float64\n",
            " 27  :                     8692 non-null   float64\n",
            " 28  .                     8692 non-null   float64\n",
            "dtypes: float64(26), int64(3)\n",
            "memory usage: 1.9 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "x_scaled = scaler.fit_transform(df.to_numpy())\n",
        "x_scaled = pd.DataFrame(x_scaled)\n",
        "\n",
        "print(\"Scaled Dataset Using MinMaxScaler\")\n",
        "x_scaled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "IUfugufuakWR",
        "outputId": "e52099e8-77fd-4268-d109-22e3c1a9941a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled Dataset Using MinMaxScaler\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0         1         2         3         4         5         6   \\\n",
              "0  0.000000  0.020010  0.019990  0.020011  0.839355  0.020018  0.020283   \n",
              "1  0.000115  0.012497  0.012483  0.012498  0.012768  0.012503  0.012666   \n",
              "2  0.000230  0.005539  0.005533  0.005541  0.005659  0.005542  0.241820   \n",
              "3  0.000345  0.901597  0.011093  0.011106  0.011347  0.011113  0.011257   \n",
              "4  0.000460  0.016670  0.016653  0.016675  0.147768  0.016679  0.016899   \n",
              "\n",
              "         7         8         9   ...        19        20        21        22  \\\n",
              "0  0.020402  0.020158  0.019916  ...  0.031915  0.000000  0.000000  0.000000   \n",
              "1  0.012740  0.012588  0.012413  ...  0.031915  0.015625  0.030303  0.002404   \n",
              "2  0.005647  0.005579  0.005467  ...  0.021277  0.015625  0.015152  0.000000   \n",
              "3  0.011324  0.011186  0.011025  ...  0.031915  0.015625  0.030303  0.002404   \n",
              "4  0.016996  0.016793  0.016581  ...  0.010638  0.000000  0.030303  0.000000   \n",
              "\n",
              "         23        24        25        26        27        28  \n",
              "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "2  0.000617  0.027778  0.044444  0.021739  0.006897  0.000000  \n",
              "3  0.000000  0.000000  0.022222  0.000000  0.000000  0.000000  \n",
              "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.004149  \n",
              "\n",
              "[5 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa188aa5-2061-418a-a41e-83735da24e05\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020010</td>\n",
              "      <td>0.019990</td>\n",
              "      <td>0.020011</td>\n",
              "      <td>0.839355</td>\n",
              "      <td>0.020018</td>\n",
              "      <td>0.020283</td>\n",
              "      <td>0.020402</td>\n",
              "      <td>0.020158</td>\n",
              "      <td>0.019916</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031915</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000115</td>\n",
              "      <td>0.012497</td>\n",
              "      <td>0.012483</td>\n",
              "      <td>0.012498</td>\n",
              "      <td>0.012768</td>\n",
              "      <td>0.012503</td>\n",
              "      <td>0.012666</td>\n",
              "      <td>0.012740</td>\n",
              "      <td>0.012588</td>\n",
              "      <td>0.012413</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031915</td>\n",
              "      <td>0.015625</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.002404</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000230</td>\n",
              "      <td>0.005539</td>\n",
              "      <td>0.005533</td>\n",
              "      <td>0.005541</td>\n",
              "      <td>0.005659</td>\n",
              "      <td>0.005542</td>\n",
              "      <td>0.241820</td>\n",
              "      <td>0.005647</td>\n",
              "      <td>0.005579</td>\n",
              "      <td>0.005467</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021277</td>\n",
              "      <td>0.015625</td>\n",
              "      <td>0.015152</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000617</td>\n",
              "      <td>0.027778</td>\n",
              "      <td>0.044444</td>\n",
              "      <td>0.021739</td>\n",
              "      <td>0.006897</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000345</td>\n",
              "      <td>0.901597</td>\n",
              "      <td>0.011093</td>\n",
              "      <td>0.011106</td>\n",
              "      <td>0.011347</td>\n",
              "      <td>0.011113</td>\n",
              "      <td>0.011257</td>\n",
              "      <td>0.011324</td>\n",
              "      <td>0.011186</td>\n",
              "      <td>0.011025</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031915</td>\n",
              "      <td>0.015625</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.002404</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000460</td>\n",
              "      <td>0.016670</td>\n",
              "      <td>0.016653</td>\n",
              "      <td>0.016675</td>\n",
              "      <td>0.147768</td>\n",
              "      <td>0.016679</td>\n",
              "      <td>0.016899</td>\n",
              "      <td>0.016996</td>\n",
              "      <td>0.016793</td>\n",
              "      <td>0.016581</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010638</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004149</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa188aa5-2061-418a-a41e-83735da24e05')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa188aa5-2061-418a-a41e-83735da24e05 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa188aa5-2061-418a-a41e-83735da24e05');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df,y, test_size=0.2, random_state=42)\n",
        "\n",
        "nb_clf = GaussianNB()\n",
        "nb_clf.fit(X_train, y_train)\n",
        "nb_pred = nb_clf.predict(X_test)\n",
        "nb_acc = accuracy_score(y_test, nb_pred)\n",
        "print(\"Naive Bayes accuracy:\", nb_acc)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_scaled,y, test_size=0.2, random_state=42)\n",
        "\n",
        "nb_clf = GaussianNB()\n",
        "nb_clf.fit(X_train, y_train)\n",
        "nb_pred = nb_clf.predict(X_test)\n",
        "nb_acc = accuracy_score(y_test, nb_pred)\n",
        "print(\"Naive Bayes accuracy:\", nb_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pwSdzWgv8nY",
        "outputId": "4c10c804-8dd4-430a-b2be-8e3acaa776a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes accuracy: 0.4974123059229442\n",
            "Naive Bayes accuracy: 0.4974123059229442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_clf = SVC(kernel='linear', C=1)\n",
        "svm_clf.fit(X_train, y_train)\n",
        "svm_pred = svm_clf.predict(X_test)\n",
        "svm_acc = accuracy_score(y_test, svm_pred)\n",
        "print(\"SVM accuracy:\", svm_acc)"
      ],
      "metadata": {
        "id": "Ck8yaZ3TwJad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_scaled,y, test_size=0.3, random_state=42)\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# fit the random forest classifier to the training data\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing data\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the random forest classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:(scaled)\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DephzXvwdtRU",
        "outputId": "d7d65a6e-fea3-480c-d0e6-1547fdb0c12a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:(scaled) 0.7630368098159509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# drop 4000>"
      ],
      "metadata": {
        "id": "7KLUDI1GdfG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/feature_dataset_8692.csv')\n",
        "y =(df.Mach<df.Mach.quantile()).replace({True:1, False:2})\n",
        "\n",
        "\n",
        "\n",
        "for column_name in df.columns:\n",
        "    column = df[column_name]\n",
        "    # Get the count of Zeros in column\n",
        "    count = (column == 0).sum()\n",
        "\n",
        "    if (count>=4000):\n",
        "       print('Count of zeros in column ', column_name, ' is : ', count)\n",
        "       df.drop(columns =column_name, inplace = True )\n",
        "\n",
        "df = df.drop(['Mach', 'LSRP12','LSRP2','NRSM','english_text','topic_distributions','word_tokens','part_of_speech','word_freq_dist'], axis=1)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "x_scaled = scaler.fit_transform(df.to_numpy())\n",
        "x_scaled = pd.DataFrame(x_scaled)\n",
        "\n",
        "print(\"Scaled Dataset Using MinMaxScaler\")\n",
        "x_scaled.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s9cKjir7desX",
        "outputId": "613110ca-2dbc-4605-8dad-c804e7df3057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of zeros in column  PRP$  is :  7318\n",
            "Count of zeros in column  CD  is :  6608\n",
            "Count of zeros in column  JJ  is :  4455\n",
            "Count of zeros in column  VBZ  is :  6161\n",
            "Count of zeros in column  DT  is :  4776\n",
            "Count of zeros in column  IN  is :  4677\n",
            "Count of zeros in column  NNS  is :  6030\n",
            "Count of zeros in column  PRP  is :  5720\n",
            "Count of zeros in column  VBP  is :  6249\n",
            "Count of zeros in column  RB  is :  5409\n",
            "Count of zeros in column  VB  is :  5788\n",
            "Count of zeros in column  CC  is :  6924\n",
            "Count of zeros in column  TO  is :  6939\n",
            "Count of zeros in column  :  is :  5862\n",
            "Count of zeros in column  #  is :  7240\n",
            "Count of zeros in column  WRB  is :  7995\n",
            "Count of zeros in column  .  is :  4976\n",
            "Count of zeros in column  WP  is :  8006\n",
            "Count of zeros in column  VBG  is :  7069\n",
            "Count of zeros in column  VBD  is :  6790\n",
            "Count of zeros in column  PDT  is :  8536\n",
            "Count of zeros in column  VBN  is :  7439\n",
            "Count of zeros in column  JJR  is :  8367\n",
            "Count of zeros in column  ``  is :  8285\n",
            "Count of zeros in column  ''  is :  8158\n",
            "Count of zeros in column  (  is :  8170\n",
            "Count of zeros in column  )  is :  7693\n",
            "Count of zeros in column  ,  is :  6980\n",
            "Count of zeros in column  JJS  is :  8266\n",
            "Count of zeros in column  $  is :  8516\n",
            "Count of zeros in column  POS  is :  7972\n",
            "Count of zeros in column  MD  is :  7393\n",
            "Count of zeros in column  WDT  is :  8478\n",
            "Count of zeros in column  NNPS  is :  8589\n",
            "Count of zeros in column  RP  is :  8332\n",
            "Count of zeros in column  SYM  is :  8673\n",
            "Count of zeros in column  RBR  is :  8555\n",
            "Count of zeros in column  EX  is :  8438\n",
            "Count of zeros in column  UH  is :  8570\n",
            "Count of zeros in column  FW  is :  8569\n",
            "Count of zeros in column  RBS  is :  8610\n",
            "Count of zeros in column  WP$  is :  8681\n",
            "Scaled Dataset Using MinMaxScaler\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0         1         2         3         4         5         6   \\\n",
              "0  0.000000  0.020010  0.019990  0.020011  0.839355  0.020018  0.020283   \n",
              "1  0.000115  0.012497  0.012483  0.012498  0.012768  0.012503  0.012666   \n",
              "2  0.000230  0.005539  0.005533  0.005541  0.005659  0.005542  0.241820   \n",
              "3  0.000345  0.901597  0.011093  0.011106  0.011347  0.011113  0.011257   \n",
              "4  0.000460  0.016670  0.016653  0.016675  0.147768  0.016679  0.016899   \n",
              "\n",
              "         7         8         9   ...    11   12        13        14        15  \\\n",
              "0  0.020402  0.020158  0.019916  ...  0.50  0.0  0.941818  0.040000  0.684211   \n",
              "1  0.012740  0.012588  0.012413  ...  0.70  0.8  0.933602  0.048358  0.912281   \n",
              "2  0.005647  0.005579  0.005467  ...  0.40  0.4  0.905508  0.066567  0.972299   \n",
              "3  0.011324  0.011186  0.011025  ...  0.55  0.1  0.894070  0.074328  0.923684   \n",
              "4  0.016996  0.016793  0.016581  ...  0.50  0.0  0.929382  0.049552  0.898026   \n",
              "\n",
              "         16        17        18        19        20  \n",
              "0  0.000960  0.058824  0.001817  0.031915  0.000000  \n",
              "1  0.001344  0.080882  0.003633  0.031915  0.000000  \n",
              "2  0.003841  0.102241  0.007266  0.021277  0.000617  \n",
              "3  0.001536  0.124183  0.002725  0.031915  0.000000  \n",
              "4  0.001344  0.066176  0.004541  0.010638  0.000000  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-217449bc-4eb6-449b-b3fb-7a00e09f9f7b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020010</td>\n",
              "      <td>0.019990</td>\n",
              "      <td>0.020011</td>\n",
              "      <td>0.839355</td>\n",
              "      <td>0.020018</td>\n",
              "      <td>0.020283</td>\n",
              "      <td>0.020402</td>\n",
              "      <td>0.020158</td>\n",
              "      <td>0.019916</td>\n",
              "      <td>...</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.941818</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.684211</td>\n",
              "      <td>0.000960</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.001817</td>\n",
              "      <td>0.031915</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000115</td>\n",
              "      <td>0.012497</td>\n",
              "      <td>0.012483</td>\n",
              "      <td>0.012498</td>\n",
              "      <td>0.012768</td>\n",
              "      <td>0.012503</td>\n",
              "      <td>0.012666</td>\n",
              "      <td>0.012740</td>\n",
              "      <td>0.012588</td>\n",
              "      <td>0.012413</td>\n",
              "      <td>...</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.933602</td>\n",
              "      <td>0.048358</td>\n",
              "      <td>0.912281</td>\n",
              "      <td>0.001344</td>\n",
              "      <td>0.080882</td>\n",
              "      <td>0.003633</td>\n",
              "      <td>0.031915</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000230</td>\n",
              "      <td>0.005539</td>\n",
              "      <td>0.005533</td>\n",
              "      <td>0.005541</td>\n",
              "      <td>0.005659</td>\n",
              "      <td>0.005542</td>\n",
              "      <td>0.241820</td>\n",
              "      <td>0.005647</td>\n",
              "      <td>0.005579</td>\n",
              "      <td>0.005467</td>\n",
              "      <td>...</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.905508</td>\n",
              "      <td>0.066567</td>\n",
              "      <td>0.972299</td>\n",
              "      <td>0.003841</td>\n",
              "      <td>0.102241</td>\n",
              "      <td>0.007266</td>\n",
              "      <td>0.021277</td>\n",
              "      <td>0.000617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000345</td>\n",
              "      <td>0.901597</td>\n",
              "      <td>0.011093</td>\n",
              "      <td>0.011106</td>\n",
              "      <td>0.011347</td>\n",
              "      <td>0.011113</td>\n",
              "      <td>0.011257</td>\n",
              "      <td>0.011324</td>\n",
              "      <td>0.011186</td>\n",
              "      <td>0.011025</td>\n",
              "      <td>...</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.894070</td>\n",
              "      <td>0.074328</td>\n",
              "      <td>0.923684</td>\n",
              "      <td>0.001536</td>\n",
              "      <td>0.124183</td>\n",
              "      <td>0.002725</td>\n",
              "      <td>0.031915</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000460</td>\n",
              "      <td>0.016670</td>\n",
              "      <td>0.016653</td>\n",
              "      <td>0.016675</td>\n",
              "      <td>0.147768</td>\n",
              "      <td>0.016679</td>\n",
              "      <td>0.016899</td>\n",
              "      <td>0.016996</td>\n",
              "      <td>0.016793</td>\n",
              "      <td>0.016581</td>\n",
              "      <td>...</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.929382</td>\n",
              "      <td>0.049552</td>\n",
              "      <td>0.898026</td>\n",
              "      <td>0.001344</td>\n",
              "      <td>0.066176</td>\n",
              "      <td>0.004541</td>\n",
              "      <td>0.010638</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-217449bc-4eb6-449b-b3fb-7a00e09f9f7b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-217449bc-4eb6-449b-b3fb-7a00e09f9f7b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-217449bc-4eb6-449b-b3fb-7a00e09f9f7b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df,y, test_size=0.2, random_state=42)\n",
        "\n",
        "nb_clf = GaussianNB()\n",
        "nb_clf.fit(X_train, y_train)\n",
        "nb_pred = nb_clf.predict(X_test)\n",
        "nb_acc = accuracy_score(y_test, nb_pred)\n",
        "print(\"Naive Bayes accuracy:\", nb_acc)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_scaled,y, test_size=0.2, random_state=42)\n",
        "\n",
        "nb_clf = GaussianNB()\n",
        "nb_clf.fit(X_train, y_train)\n",
        "nb_pred = nb_clf.predict(X_test)\n",
        "nb_acc = accuracy_score(y_test, nb_pred)\n",
        "print(\"Naive Bayes accuracy:\", nb_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohmXXjyId9hO",
        "outputId": "b9ef38be-00e8-41f9-d0de-09c96d40bd83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes accuracy: 0.49856239217941345\n",
            "Naive Bayes accuracy: 0.496262219666475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df,y, test_size=0.2, random_state=42)\n",
        "\n",
        "svm_clf = SVC(kernel='linear', C=1)\n",
        "svm_clf.fit(X_train, y_train)\n",
        "svm_pred = svm_clf.predict(X_test)\n",
        "svm_acc = accuracy_score(y_test, svm_pred)\n",
        "print(\"SVM accuracy:\", svm_acc)"
      ],
      "metadata": {
        "id": "EpSK1iNDd-a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x_scaled,y, test_size=0.2, random_state=42)\n",
        "\n",
        "svm_clf = SVC(kernel='linear', C=1)\n",
        "svm_clf.fit(X_train, y_train)\n",
        "svm_pred = svm_clf.predict(X_test)\n",
        "svm_acc = accuracy_score(y_test, svm_pred)\n",
        "print(\"SVM accuracy:\", svm_acc)"
      ],
      "metadata": {
        "id": "dXxVSfFkeCTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df,y, test_size=0.3, random_state=42)\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# fit the random forest classifier to the training data\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing data\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the random forest classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:(scaled)\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-_u3bgxeP4v",
        "outputId": "8145b7e6-0452-4515-9433-522a39a5cdfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:(scaled) 0.7557515337423313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_scaled,y, test_size=0.3, random_state=42)\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# fit the random forest classifier to the training data\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the testing data\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the random forest classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:(scaled)\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVTr0foxdySZ",
        "outputId": "c2271536-f8da-4203-dbab-c15dff59ec8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:(scaled) 0.7523006134969326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble"
      ],
      "metadata": {
        "id": "hCU84OpUh5MP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/feature_dataset_8692.csv')\n",
        "y =(df.Mach<df.Mach.quantile()).replace({True:1, False:2})\n",
        "\n",
        "\n",
        "\n",
        "for column_name in df.columns:\n",
        "    column = df[column_name]\n",
        "    # Get the count of Zeros in column\n",
        "    count = (column == 0).sum()\n",
        "\n",
        "    if (count>=6000):\n",
        "       df.drop(columns =column_name, inplace = True )\n",
        "\n",
        "df = df.drop(['Mach', 'LSRP12','LSRP2','NRSM','english_text','topic_distributions','word_tokens','part_of_speech','word_freq_dist'], axis=1)\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zom19gsziH_A",
        "outputId": "21950a09-c7d8-4be9-846d-40113c275a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8692 entries, 0 to 8691\n",
            "Data columns (total 29 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Unnamed: 0            8692 non-null   int64  \n",
            " 1   topic_0               8692 non-null   float64\n",
            " 2   topic_1               8692 non-null   float64\n",
            " 3   topic_2               8692 non-null   float64\n",
            " 4   topic_3               8692 non-null   float64\n",
            " 5   topic_4               8692 non-null   float64\n",
            " 6   topic_5               8692 non-null   float64\n",
            " 7   topic_6               8692 non-null   float64\n",
            " 8   topic_7               8692 non-null   float64\n",
            " 9   topic_8               8692 non-null   float64\n",
            " 10  topic_9               8692 non-null   float64\n",
            " 11  polarity              8692 non-null   float64\n",
            " 12  subjectivity          8692 non-null   float64\n",
            " 13  flesch_reading_ease   8692 non-null   float64\n",
            " 14  flesch_kincaid_grade  8692 non-null   float64\n",
            " 15  lexical_density       8692 non-null   float64\n",
            " 16  word_count            8692 non-null   int64  \n",
            " 17  avg_word_length       8692 non-null   float64\n",
            " 18  stopword_count        8692 non-null   int64  \n",
            " 19  NN                    8692 non-null   float64\n",
            " 20  JJ                    8692 non-null   float64\n",
            " 21  DT                    8692 non-null   float64\n",
            " 22  IN                    8692 non-null   float64\n",
            " 23  NNP                   8692 non-null   float64\n",
            " 24  PRP                   8692 non-null   float64\n",
            " 25  RB                    8692 non-null   float64\n",
            " 26  VB                    8692 non-null   float64\n",
            " 27  :                     8692 non-null   float64\n",
            " 28  .                     8692 non-null   float64\n",
            "dtypes: float64(26), int64(3)\n",
            "memory usage: 1.9 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "x_scaled = scaler.fit_transform(df.to_numpy())\n",
        "x_scaled = pd.DataFrame(x_scaled)\n",
        "\n",
        "print(\"Scaled Dataset Using MinMaxScaler\")\n",
        "x_scaled.head()\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "nb = GaussianNB()\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "xgboost = xgb.XGBClassifier(random_state=42)\n",
        "\n",
        "ensemble = VotingClassifier(estimators=[('nb', nb), ('rf', rf), ('dt', dt), ('xgboost', xgboost)], voting='hard')\n",
        "\n",
        "\n",
        "ensemble.fit(X_train, y_train)\n",
        "\n",
        "y_pred = ensemble.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqLqfp_eh40C",
        "outputId": "069eca14-10ed-4ded-f9ec-296082d6d4ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled Dataset Using MinMaxScaler\n",
            "Accuracy: 0.9785276073619632\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      1.00      0.98      1302\n",
            "           2       1.00      0.96      0.98      1306\n",
            "\n",
            "    accuracy                           0.98      2608\n",
            "   macro avg       0.98      0.98      0.98      2608\n",
            "weighted avg       0.98      0.98      0.98      2608\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "sns.heatmap(cm, annot=True, cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "OZgWBFD-lyiz",
        "outputId": "2bbba9a8-7fb6-4076-a3a4-80e19436856d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[1296    6]\n",
            " [  50 1256]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "corr matrix and statistical analysis"
      ],
      "metadata": {
        "id": "vkfiYBz1wZTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_mach = pd.concat([x, y], axis = 1)\n"
      ],
      "metadata": {
        "id": "IHAV-tFPojtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f = plt.figure(figsize=(19, 15))\n",
        "plt.matshow(df_mach.corr(), fignum=f.number)\n",
        "plt.xticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=14, rotation=45)\n",
        "plt.yticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=14)\n",
        "cb = plt.colorbar()\n",
        "cb.ax.tick_params(labelsize=14)\n",
        "plt.title('Correlation Matrix', fontsize=16);"
      ],
      "metadata": {
        "id": "KWXBxvkineSJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}